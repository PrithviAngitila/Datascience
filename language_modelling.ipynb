{"nbformat_minor": 2, "cells": [{"execution_count": 1, "cell_type": "code", "source": "!pip install tensorflow\n!pip install keras", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Collecting tensorflow\n  Downloading https://files.pythonhosted.org/packages/db/a4/474ea77f41fbcd02d382debef1053de769db2ea0e7c29c275ddd0098f832/tensorflow-1.10.0-cp34-cp34m-manylinux1_x86_64.whl (59.0MB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 59.0MB 6.3kB/s eta 0:00:01    38% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008c                   | 23.0MB 10.3MB/s eta 0:00:04    40% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0089                   | 23.7MB 7.8MB/s eta 0:00:05    47% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008f                | 27.9MB 15.4MB/s eta 0:00:03    55% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008a              | 32.7MB 4.4MB/s eta 0:00:06    82% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008e     | 48.5MB 10.4MB/s eta 0:00:02    82% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008c     | 49.0MB 7.0MB/s eta 0:00:02\u00ef\u00bf\u00bd\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088 | 57.1MB 17.1MB/s eta 0:00:01\n\u001b[?25hCollecting absl-py>=0.1.6 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/96/5d/18feb90462c8edaae71305716c7e8bac479fc9dface63221f808a6b95880/absl-py-0.3.0.tar.gz (84kB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 92kB 4.0MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools<=39.1.0 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages/setuptools-27.2.0-py3.4.egg (from tensorflow)\nRequirement already satisfied: wheel>=0.26 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from tensorflow)\nCollecting gast>=0.2.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\nCollecting grpcio>=1.8.6 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/48/ad/44d573b2ae87a12806827329e9d22331c1e27d227c20a878499accd06ee0/grpcio-1.14.1-cp34-cp34m-manylinux1_x86_64.whl (9.3MB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 9.3MB 56kB/s  eta 0:00:01    43% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088                  | 4.1MB 26.9MB/s eta 0:00:01\n\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\nCollecting termcolor>=1.1.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\nCollecting numpy<=1.14.5,>=1.13.3 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/6a/69/24b5d5c2466df479ed42f970a61eb570f57d8a20bd79e44ec39ee37ded12/numpy-1.14.5-cp34-cp34m-manylinux1_x86_64.whl (12.1MB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 12.1MB 33kB/s  eta 0:00:01  3% |\u00e2\u0096\u0088                               | 389kB 10.6MB/s eta 0:00:02    64% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008b           | 7.8MB 19.1MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard<1.11.0,>=1.10.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 3.3MB 175kB/s ta 0:00:011\n\u001b[?25hCollecting protobuf>=3.6.0 (from tensorflow)\n  Downloading https://files.pythonhosted.org/packages/90/f6/075ce27278f11a0313f52bfd48dec6e1ff45dc13f28cdce12be57bfbcadb/protobuf-3.6.0-cp34-cp34m-manylinux1_x86_64.whl (7.1MB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 7.1MB 56kB/s  eta 0:00:01   9% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008f                            | 706kB 9.0MB/s eta 0:00:01    17% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008a                          | 1.3MB 16.0MB/s eta 0:00:01    22% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008e                        | 1.6MB 9.1MB/s eta 0:00:01    28% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u008e                      | 2.1MB 9.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from tensorflow)\nCollecting markdown>=2.6.8 (from tensorboard<1.11.0,>=1.10.0->tensorflow)\n  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 81kB 4.1MB/s ta 0:00:011\n\u001b[?25hCollecting werkzeug>=0.11.10 (from tensorboard<1.11.0,>=1.10.0->tensorflow)\n  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 327kB 1.8MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: absl-py, gast, termcolor\n  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/4c/16/ef/e36a23f2432e9220f8845f94e2c3abd39e7d9d1cd458d3159d\n  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\nSuccessfully built absl-py gast termcolor\nInstalling collected packages: absl-py, gast, grpcio, astor, termcolor, numpy, markdown, protobuf, werkzeug, tensorboard, tensorflow\n  Found existing installation: numpy 1.11.3\n    Uninstalling numpy-1.11.3:\n      Successfully uninstalled numpy-1.11.3\n  Found existing installation: Werkzeug 0.10.4\n\u001b[31m    DEPRECATION: Uninstalling a distutils installed project (werkzeug) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\u001b[0m\n    Uninstalling Werkzeug-0.10.4:\n      Successfully uninstalled Werkzeug-0.10.4\nSuccessfully installed absl-py-0.3.0 astor-0.7.1 gast-0.2.0 grpcio-1.14.1 markdown-2.6.11 numpy-1.14.5 protobuf-3.6.0 tensorboard-1.10.0 tensorflow-1.10.0 termcolor-1.1.0 werkzeug-0.14.1\nCollecting keras\n  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 307kB 1.1MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied: pyyaml in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from keras)\nRequirement already satisfied: six>=1.9.0 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from keras)\nCollecting keras-preprocessing==1.0.2 (from keras)\n  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\nRequirement already satisfied: scipy>=0.14 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from keras)\nRequirement already satisfied: numpy>=1.9.1 in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from keras)\nCollecting keras-applications==1.0.4 (from keras)\n  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n\u001b[K    100% |\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088\u00e2\u0096\u0088| 51kB 2.4MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: h5py in /home/nbuser/anaconda3_23/lib/python3.4/site-packages (from keras)\nInstalling collected packages: keras-preprocessing, keras-applications, keras\nSuccessfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2\n"}], "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function", "outputs": [], "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "import os\nimport gzip\nimport csv\nimport numpy as np\n", "outputs": [], "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": "import tensorflow as tf", "outputs": [], "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": "%matplotlib inline\n\nimport matplotlib\nimport matplotlib.pyplot as plt", "outputs": [{"output_type": "stream", "name": "stderr", "text": "/home/nbuser/anaconda3_23/lib/python3.4/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n/home/nbuser/anaconda3_23/lib/python3.4/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"}], "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": "from six.moves import urllib", "outputs": [], "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "print(np.__version__)\nprint(tf.__version__)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1.14.5\n1.10.0\n"}], "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "URL_PATH = 'http://ai.stanford.edu/~btaskar/ocr/letter.data.gz'\nDOWNLOADED_FILENAME = 'letter.data.gz'\n\ndef download_data():\n    if not os.path.exists(DOWNLOADED_FILENAME):\n        filename, _ = urllib.request.urlretrieve(URL_PATH, DOWNLOADED_FILENAME)\n    \n    print('Found and verified file from this path: ', URL_PATH)\n    print('Downloaded file: ', DOWNLOADED_FILENAME)", "outputs": [], "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": "from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.callbacks import EarlyStopping\n\n#   Supress warning and informational messages\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ", "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}], "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": "download_data()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Found and verified file from this path:  http://ai.stanford.edu/~btaskar/ocr/letter.data.gz\nDownloaded file:  letter.data.gz\n"}], "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": "def read_lines():\n    with gzip.open(DOWNLOADED_FILENAME, 'rt') as f:\n        reader = csv.reader(f, delimiter='\\t')\n        lines = list(reader)\n\n        return lines", "outputs": [], "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": "lines = read_lines()", "outputs": [], "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "lines[0]", "outputs": [{"execution_count": 13, "output_type": "execute_result", "data": {"text/plain": "['1',\n 'o',\n '2',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '1',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '0',\n '1',\n '1',\n '1',\n '1',\n '1',\n '0',\n '0',\n '0',\n '1',\n '0',\n '0',\n '0',\n '1',\n '1',\n '0',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '1',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '0',\n '1',\n '1',\n '1',\n '0',\n '0',\n '0',\n '1',\n '1',\n '1',\n '0',\n '1',\n '1',\n '1',\n '1',\n '1',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '0',\n '']"}, "metadata": {}}], "metadata": {}}, {"execution_count": 14, "cell_type": "code", "source": "len(lines)", "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "52152"}, "metadata": {}}], "metadata": {}}, {"execution_count": 15, "cell_type": "code", "source": "def get_features_labels(lines):\n    lines = sorted(lines, key=lambda x: int(x[0]))\n    data, target = [], []\n    \n    next_id = -1\n    \n    word = []\n    word_pixels = []\n\n    for line in lines:\n         # The index for the next_id column\n        next_id = int(line[2])\n\n        # An image for a single character, reshaped\n        pixels = np.array([int(x) for x in line[6:134]])\n        pixels = pixels.reshape((16, 8))\n        \n        # Word pixels are a list of 16x8 images which form a single word\n        word_pixels.append(pixels)\n        \n        # Append together the characters which make up a word\n        word.append(line[1])\n        \n        if next_id == -1:\n            data.append(word_pixels)\n            target.append(word)\n\n            word = []\n            word_pixels = []\n\n\n    return data, target", "outputs": [], "metadata": {}}, {"execution_count": 16, "cell_type": "code", "source": "data, target = get_features_labels(lines)", "outputs": [], "metadata": {}}, {"execution_count": 17, "cell_type": "code", "source": "len(data), len(target)", "outputs": [{"execution_count": 17, "output_type": "execute_result", "data": {"text/plain": "(6877, 6877)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 18, "cell_type": "code", "source": "data[0]", "outputs": [{"execution_count": 18, "output_type": "execute_result", "data": {"text/plain": "[array([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 1, 1, 1, 0, 0, 0, 0],\n        [0, 1, 1, 1, 1, 1, 0, 0],\n        [0, 1, 0, 0, 0, 1, 1, 0],\n        [1, 1, 0, 0, 0, 0, 1, 1],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 1, 1],\n        [1, 0, 0, 0, 1, 1, 1, 0],\n        [1, 1, 1, 1, 1, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 1, 1, 1, 1, 1, 1, 0],\n        [1, 1, 0, 1, 1, 0, 1, 1],\n        [1, 0, 1, 1, 0, 0, 0, 1],\n        [1, 0, 1, 1, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 0, 0, 1, 1, 0],\n        [1, 0, 1, 0, 1, 1, 1, 0],\n        [1, 0, 1, 1, 1, 0, 1, 0],\n        [1, 0, 0, 1, 0, 0, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 1, 0, 0, 0, 0],\n        [0, 1, 1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 1, 1, 0, 0],\n        [1, 0, 0, 1, 0, 1, 1, 0],\n        [1, 1, 1, 0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 1, 1, 0],\n        [0, 0, 0, 1, 1, 0, 1, 0],\n        [0, 0, 1, 1, 0, 0, 1, 0],\n        [1, 1, 1, 0, 0, 0, 1, 0],\n        [1, 1, 1, 0, 0, 0, 1, 0],\n        [1, 1, 0, 0, 0, 0, 1, 0],\n        [1, 1, 0, 0, 0, 0, 1, 0],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0, 0, 0, 0],\n        [0, 1, 1, 0, 0, 0, 0, 0],\n        [0, 1, 1, 1, 0, 0, 0, 0],\n        [0, 1, 0, 1, 1, 0, 0, 0],\n        [0, 1, 1, 0, 1, 0, 0, 0],\n        [0, 0, 1, 0, 1, 1, 0, 0],\n        [0, 0, 1, 0, 0, 1, 1, 0],\n        [0, 0, 1, 1, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0, 0, 1, 0],\n        [0, 1, 1, 1, 0, 0, 1, 0],\n        [1, 1, 0, 1, 0, 1, 1, 0],\n        [1, 0, 0, 1, 1, 1, 0, 0],\n        [1, 0, 1, 1, 1, 0, 0, 1],\n        [1, 1, 1, 0, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 1, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0],\n        [0, 0, 1, 1, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 1, 1, 1],\n        [0, 0, 1, 1, 1, 0, 0, 1],\n        [0, 0, 1, 0, 0, 0, 0, 1],\n        [0, 1, 1, 0, 0, 0, 0, 1],\n        [1, 1, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [1, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 1, 1, 1, 1, 0, 0, 0],\n        [1, 1, 0, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0, 0, 0],\n        [1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1],\n        [0, 0, 0, 0, 0, 0, 1, 1],\n        [0, 0, 0, 0, 0, 1, 1, 0],\n        [0, 0, 0, 0, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 1, 0, 0]])]"}, "metadata": {}}], "metadata": {}}, {"execution_count": 19, "cell_type": "code", "source": "target[567]", "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "['e', 'v', 'v', 'i', 'n', 'g']"}, "metadata": {}}], "metadata": {}}, {"execution_count": 20, "cell_type": "code", "source": "def pad_features_labels(data, target):    \n    max_length = max(len(x) for x in target)\n    \n    # Set up image representations for the empty string (all pixels set to 0)\n    padding = np.zeros((16, 8))\n\n    # Pad the image data with the empty string images\n    data = [x + ([padding] * (max_length - len(x))) for x in data]\n    \n    # Pad the words with empty string characters\n    target = [x + ([''] * (max_length - len(x))) for x in target]\n    \n    return np.array(data), np.array(target)", "outputs": [], "metadata": {}}, {"execution_count": 21, "cell_type": "code", "source": "padded_data, padded_target = pad_features_labels(data, target)", "outputs": [], "metadata": {}}, {"execution_count": 22, "cell_type": "code", "source": "padded_data.shape", "outputs": [{"execution_count": 22, "output_type": "execute_result", "data": {"text/plain": "(6877, 14, 16, 8)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 23, "cell_type": "code", "source": "padded_target[:10]", "outputs": [{"execution_count": 23, "output_type": "execute_result", "data": {"text/plain": "array([['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', ''],\n       ['o', 'm', 'm', 'a', 'n', 'd', 'i', 'n', 'g', '', '', '', '', '']],\n      dtype='<U1')"}, "metadata": {}}], "metadata": {}}, {"execution_count": 24, "cell_type": "code", "source": "padded_target[200:210]", "outputs": [{"execution_count": 24, "output_type": "execute_result", "data": {"text/plain": "array([['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', ''],\n       ['m', 'b', 'r', 'a', 'c', 'e', 's', '', '', '', '', '', '', '']],\n      dtype='<U1')"}, "metadata": {}}], "metadata": {}}, {"execution_count": 25, "cell_type": "code", "source": "word_length = len(padded_target[0])", "outputs": [], "metadata": {}}, {"execution_count": 26, "cell_type": "code", "source": "word_length", "outputs": [{"execution_count": 26, "output_type": "execute_result", "data": {"text/plain": "14"}, "metadata": {}}], "metadata": {}}, {"execution_count": 27, "cell_type": "code", "source": "padded_data.shape", "outputs": [{"execution_count": 27, "output_type": "execute_result", "data": {"text/plain": "(6877, 14, 16, 8)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 28, "cell_type": "code", "source": "padded_data.shape[:2] + (-1,)", "outputs": [{"execution_count": 28, "output_type": "execute_result", "data": {"text/plain": "(6877, 14, -1)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 29, "cell_type": "code", "source": "reshaped_data = padded_data.reshape(padded_data.shape[:2] + (-1,))", "outputs": [], "metadata": {}}, {"execution_count": 30, "cell_type": "code", "source": "reshaped_data.shape", "outputs": [{"execution_count": 30, "output_type": "execute_result", "data": {"text/plain": "(6877, 14, 128)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 31, "cell_type": "code", "source": "padded_target.shape", "outputs": [{"execution_count": 31, "output_type": "execute_result", "data": {"text/plain": "(6877, 14)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 32, "cell_type": "code", "source": "padded_target.shape + (26,)", "outputs": [{"execution_count": 32, "output_type": "execute_result", "data": {"text/plain": "(6877, 14, 26)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 33, "cell_type": "code", "source": "one_hot_target = np.zeros(padded_target.shape + (26,))", "outputs": [], "metadata": {}}, {"execution_count": 34, "cell_type": "code", "source": "for index, letter in np.ndenumerate(padded_target):\n    if letter:\n        one_hot_target[index][ord(letter) - ord('a')] = 1", "outputs": [], "metadata": {}}, {"execution_count": 35, "cell_type": "code", "source": "one_hot_target[0]", "outputs": [{"execution_count": 35, "output_type": "execute_result", "data": {"text/plain": "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"}, "metadata": {}}], "metadata": {}}, {"execution_count": 36, "cell_type": "code", "source": "shuffled_indices = np.random.permutation(len(reshaped_data))\n\nshuffled_data = reshaped_data[shuffled_indices]\nshuffled_target = one_hot_target[shuffled_indices]", "outputs": [], "metadata": {}}, {"execution_count": 37, "cell_type": "code", "source": "split = int(0.66 * len(shuffled_data))\n\ntrain_data = shuffled_data[:split]\ntrain_target = shuffled_target[:split]\n\ntest_data = shuffled_data[split:]\ntest_target = shuffled_target[split:]", "outputs": [], "metadata": {}}, {"execution_count": 38, "cell_type": "code", "source": "train_data.shape", "outputs": [{"execution_count": 38, "output_type": "execute_result", "data": {"text/plain": "(4538, 14, 128)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 39, "cell_type": "code", "source": "train_target.shape", "outputs": [{"execution_count": 39, "output_type": "execute_result", "data": {"text/plain": "(4538, 14, 26)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 40, "cell_type": "code", "source": "test_data.shape", "outputs": [{"execution_count": 40, "output_type": "execute_result", "data": {"text/plain": "(2339, 14, 128)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 41, "cell_type": "code", "source": "test_target.shape", "outputs": [{"execution_count": 41, "output_type": "execute_result", "data": {"text/plain": "(2339, 14, 26)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 42, "cell_type": "code", "source": "_, num_steps, num_inputs = train_data.shape", "outputs": [], "metadata": {}}, {"execution_count": 43, "cell_type": "code", "source": "num_inputs", "outputs": [{"execution_count": 43, "output_type": "execute_result", "data": {"text/plain": "128"}, "metadata": {}}], "metadata": {}}, {"execution_count": 44, "cell_type": "code", "source": "np.array(train_target.shape)", "outputs": [{"execution_count": 44, "output_type": "execute_result", "data": {"text/plain": "array([4538,   14,   26])"}, "metadata": {}}], "metadata": {}}, {"execution_count": 45, "cell_type": "code", "source": "num_classes = train_target.shape[2]", "outputs": [], "metadata": {}}, {"execution_count": 46, "cell_type": "code", "source": "num_classes", "outputs": [{"execution_count": 46, "output_type": "execute_result", "data": {"text/plain": "26"}, "metadata": {}}], "metadata": {}}, {"execution_count": 47, "cell_type": "code", "source": "train_target_reshaped=train_target.reshape(train_target.shape[0],-1)\ntrain_target_reshaped.shape", "outputs": [{"execution_count": 47, "output_type": "execute_result", "data": {"text/plain": "(4538, 364)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 48, "cell_type": "code", "source": "test_target_reshaped=test_target.reshape(test_target.shape[0],-1)\ntest_target_reshaped.shape", "outputs": [{"execution_count": 48, "output_type": "execute_result", "data": {"text/plain": "(2339, 364)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 49, "cell_type": "code", "source": "#run keras model here\n\nfrom keras.layers import Flatten,LSTMCell,Dropout,GRU\nmodel = Sequential()\n#keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.3, recurrent_dropout=0.3, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)\nmodel.add(GRU(units=150,\n    input_shape = (14,128),dropout=0.3, recurrent_dropout=0.3,activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None,implementation=1,unroll=True))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(364,activation='sigmoid'))\n\n", "outputs": [], "metadata": {}}, {"execution_count": 50, "cell_type": "code", "source": "#keras\nmodel.compile(loss='binary_crossentropy',  \n            optimizer='RMSProp',              \n            metrics=['accuracy'])\n", "outputs": [], "metadata": {}}, {"execution_count": 51, "cell_type": "code", "source": "#keras\nBATCH_SIZE = 24\nEPOCHS = 5\ncbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\nmodel.fit(train_data, train_target_reshaped, BATCH_SIZE, epochs=EPOCHS, \n             validation_data=(test_data, test_target_reshaped),\n            callbacks=[cbk_early_stopping] )", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Train on 4538 samples, validate on 2339 samples\nEpoch 1/5\n4538/4538 [==============================] - 20s 4ms/step - loss: 0.1036 - acc: 0.9739 - val_loss: 0.0778 - val_acc: 0.9793\nEpoch 2/5\n4538/4538 [==============================] - 14s 3ms/step - loss: 0.0743 - acc: 0.9791 - val_loss: 0.0663 - val_acc: 0.9793\nEpoch 3/5\n4538/4538 [==============================] - 14s 3ms/step - loss: 0.0644 - acc: 0.9791 - val_loss: 0.0568 - val_acc: 0.9796\nEpoch 4/5\n4538/4538 [==============================] - 15s 3ms/step - loss: 0.0560 - acc: 0.9796 - val_loss: 0.0502 - val_acc: 0.9802\nEpoch 5/5\n4538/4538 [==============================] - 13s 3ms/step - loss: 0.0497 - acc: 0.9807 - val_loss: 0.0432 - val_acc: 0.9823\n"}, {"execution_count": 51, "output_type": "execute_result", "data": {"text/plain": "<keras.callbacks.History at 0x7f8811f8aef0>"}, "metadata": {}}], "metadata": {}}, {"execution_count": 52, "cell_type": "code", "source": "#keras\nscore, acc = model.evaluate(test_data, test_target_reshaped,\n                            batch_size=BATCH_SIZE)\nprint('test score:', score, ' test accuracy:', acc)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "2339/2339 [==============================] - 2s 906us/step\ntest score: 0.043177195990720126  test accuracy: 0.9823419346214105\n"}], "metadata": {}}, {"execution_count": 53, "cell_type": "code", "source": "#tensorflow goes from  here", "outputs": [], "metadata": {}}, {"execution_count": 54, "cell_type": "code", "source": "tf.reset_default_graph()", "outputs": [], "metadata": {}}, {"execution_count": 55, "cell_type": "code", "source": "X = tf.placeholder(tf.float64, [None, num_steps, num_inputs])\n\ny = tf.placeholder(tf.float64, [None, num_steps, num_classes])", "outputs": [], "metadata": {}}, {"execution_count": 56, "cell_type": "code", "source": "# All real characters will have a max value of 1, padded characters will be represented by 0s\nused = tf.sign(tf.reduce_max(tf.abs(X), reduction_indices=2))\n\n# Sum up the number of real characters for each word\nlength = tf.reduce_sum(used, reduction_indices=1)\nsequence_length = tf.cast(length, tf.int32)", "outputs": [], "metadata": {}}, {"execution_count": 57, "cell_type": "code", "source": "sequence_length", "outputs": [{"execution_count": 57, "output_type": "execute_result", "data": {"text/plain": "<tf.Tensor 'Cast:0' shape=(?,) dtype=int32>"}, "metadata": {}}], "metadata": {}}, {"execution_count": 58, "cell_type": "code", "source": "num_neurons = 300", "outputs": [], "metadata": {}}, {"execution_count": 59, "cell_type": "code", "source": "cell = tf.nn.rnn_cell.GRUCell(num_neurons)", "outputs": [], "metadata": {}}, {"execution_count": 60, "cell_type": "code", "source": "output, _ = tf.nn.dynamic_rnn(cell, X, dtype=tf.float64, sequence_length=sequence_length)", "outputs": [], "metadata": {}}, {"execution_count": 61, "cell_type": "code", "source": "output.shape", "outputs": [{"execution_count": 61, "output_type": "execute_result", "data": {"text/plain": "TensorShape([Dimension(None), Dimension(14), Dimension(300)])"}, "metadata": {}}], "metadata": {}}, {"execution_count": 62, "cell_type": "code", "source": "weight = tf.Variable(tf.truncated_normal([num_neurons, num_classes], stddev=0.01, dtype=tf.float64))", "outputs": [], "metadata": {}}, {"execution_count": 63, "cell_type": "code", "source": "bias = tf.Variable(tf.constant(0.1, shape=[num_classes], dtype=tf.float64))", "outputs": [], "metadata": {}}, {"execution_count": 64, "cell_type": "code", "source": "flattened_output = tf.reshape(output, [-1, num_neurons])", "outputs": [], "metadata": {}}, {"execution_count": 65, "cell_type": "code", "source": "flattened_output", "outputs": [{"execution_count": 65, "output_type": "execute_result", "data": {"text/plain": "<tf.Tensor 'Reshape:0' shape=(?, 300) dtype=float64>"}, "metadata": {}}], "metadata": {}}, {"execution_count": 66, "cell_type": "code", "source": "logits = tf.matmul(flattened_output, weight) + bias", "outputs": [], "metadata": {}}, {"execution_count": 67, "cell_type": "code", "source": "logits_reshaped = tf.reshape(logits, [-1, num_steps, num_classes])", "outputs": [], "metadata": {}}, {"execution_count": 68, "cell_type": "code", "source": "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "WARNING:tensorflow:From <ipython-input-68-af49d04ec701>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n\n"}], "metadata": {}}, {"execution_count": 69, "cell_type": "code", "source": "loss = tf.reduce_mean(cross_entropy)", "outputs": [], "metadata": {}}, {"execution_count": 70, "cell_type": "code", "source": "mistakes = tf.not_equal(\n            tf.argmax(y, 2), tf.argmax(logits_reshaped, 2))\nmistakes = tf.cast(mistakes, tf.float64)\nmask = tf.sign(tf.reduce_max(tf.abs(y), reduction_indices=2))\nmistakes *= mask", "outputs": [], "metadata": {}}, {"execution_count": 71, "cell_type": "code", "source": "mistakes = tf.reduce_sum(mistakes, reduction_indices=1)\nmistakes /= tf.cast(sequence_length, tf.float64)", "outputs": [], "metadata": {}}, {"execution_count": 72, "cell_type": "code", "source": "error = tf.reduce_mean(mistakes)", "outputs": [], "metadata": {}}, {"execution_count": 73, "cell_type": "code", "source": "optimizer = tf.train.RMSPropOptimizer(0.002)", "outputs": [], "metadata": {}}, {"execution_count": 74, "cell_type": "code", "source": "gradient = optimizer.compute_gradients(loss)", "outputs": [], "metadata": {}}, {"execution_count": 75, "cell_type": "code", "source": "optimize = optimizer.apply_gradients(gradient)", "outputs": [], "metadata": {}}, {"execution_count": 76, "cell_type": "code", "source": "def batched(data, target, batch_size):\n    epoch = 0\n    offset = 0\n    while True:\n        old_offset = offset\n        offset = (offset + batch_size) % (target.shape[0] - batch_size)\n\n        # Offset wrapped around to the beginning so new epoch\n        if offset < old_offset:\n            # New epoch, need to shuffle data\n            shuffled_indices = np.random.permutation(len(data))\n            \n            data = data[shuffled_indices]\n            target = target[shuffled_indices]\n\n            epoch += 1\n\n        batch_data = data[offset:(offset + batch_size), :]\n        \n        batch_target = target[offset:(offset + batch_size), :]\n\n        yield batch_data, batch_target, epoch", "outputs": [], "metadata": {}}, {"execution_count": 77, "cell_type": "code", "source": "batch_size = 20\nbatches = batched(train_data, train_target, batch_size)", "outputs": [], "metadata": {}}, {"execution_count": 78, "cell_type": "code", "source": "epochs = 5", "outputs": [], "metadata": {}}, {"execution_count": 79, "cell_type": "code", "source": "train_target.shape", "outputs": [{"execution_count": 79, "output_type": "execute_result", "data": {"text/plain": "(4538, 14, 26)"}, "metadata": {}}], "metadata": {}}, {"execution_count": 80, "cell_type": "code", "source": "with tf.Session() as sess:\n    \n    sess.run(tf.global_variables_initializer())\n\n    for index, batch in enumerate(batches):\n        batch_data = batch[0]\n        batch_target = batch[1]\n    \n        epoch = batch[2]\n\n        if epoch >= epochs:\n            break\n        \n        feed = {X: batch_data, y: batch_target}\n        train_error, _ = sess.run([error, optimize], feed)\n        \n        print('{}: {:3.6f}%'.format(index + 1, 100 * train_error))\n\n    test_feed = {X: test_data, y: test_target}\n    test_error, _ = sess.run([error, optimize], test_feed)\n    \n    print('Test error: {:3.6f}%'.format(100 * test_error))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1: 91.039502%\n2: 95.327381%\n3: 94.518162%\n4: 97.267857%\n5: 92.013889%\n6: 94.285714%\n7: 92.058983%\n8: 93.303571%\n9: 93.273810%\n10: 92.706349%\n11: 92.460317%\n12: 95.311147%\n13: 95.183150%\n14: 93.535354%\n15: 95.041667%\n16: 93.136724%\n17: 94.173535%\n18: 90.448718%\n19: 93.823232%\n20: 91.047869%\n21: 93.286977%\n22: 91.647436%\n23: 88.918651%\n24: 94.384921%\n25: 87.625000%\n26: 95.041667%\n27: 92.308150%\n28: 91.123016%\n29: 93.318903%\n30: 91.917707%\n31: 90.496032%\n32: 87.388653%\n33: 87.304834%\n34: 88.094114%\n35: 82.867133%\n36: 92.140818%\n37: 90.368687%\n38: 84.541126%\n39: 94.363400%\n40: 91.505952%\n41: 84.569084%\n42: 87.162463%\n43: 90.519481%\n44: 82.241522%\n45: 82.644481%\n46: 90.932540%\n47: 86.301407%\n48: 87.905067%\n49: 85.585317%\n50: 91.678211%\n51: 91.545940%\n52: 91.356061%\n53: 89.486111%\n54: 91.934524%\n55: 87.490454%\n56: 86.856782%\n57: 88.200397%\n58: 91.691281%\n59: 87.630897%\n60: 85.015512%\n61: 87.077381%\n62: 91.602453%\n63: 88.821068%\n64: 92.073232%\n65: 89.683150%\n66: 90.611056%\n67: 87.329129%\n68: 81.253205%\n69: 87.264194%\n70: 90.215368%\n71: 87.180500%\n72: 87.644481%\n73: 87.736541%\n74: 91.270743%\n75: 88.050866%\n76: 89.547924%\n77: 91.126984%\n78: 87.579976%\n79: 89.420635%\n80: 84.827381%\n81: 88.066697%\n82: 88.425866%\n83: 83.794553%\n84: 84.680805%\n85: 79.120671%\n86: 81.906746%\n87: 88.299603%\n88: 85.159993%\n89: 87.542569%\n90: 84.268939%\n91: 82.077686%\n92: 86.460317%\n93: 84.533189%\n94: 80.121101%\n95: 81.615940%\n96: 80.693182%\n97: 90.041972%\n98: 77.577686%\n99: 80.146465%\n100: 89.355159%\n101: 87.045094%\n102: 84.297924%\n103: 82.327520%\n104: 86.677198%\n105: 82.235209%\n106: 87.662948%\n107: 90.634199%\n108: 80.324495%\n109: 82.371947%\n110: 77.529068%\n111: 74.277237%\n112: 85.775794%\n113: 72.265762%\n114: 79.784105%\n115: 74.611111%\n116: 85.775794%\n117: 83.744949%\n118: 86.306999%\n119: 78.383561%\n120: 82.346306%\n121: 77.399184%\n122: 81.096320%\n123: 75.713745%\n124: 71.110639%\n125: 79.314782%\n126: 75.340881%\n127: 81.925519%\n128: 83.646978%\n129: 72.060204%\n130: 80.214286%\n131: 80.804792%\n132: 76.115232%\n133: 79.355478%\n134: 76.301227%\n135: 75.494186%\n136: 73.702936%\n137: 70.605894%\n138: 73.117369%\n139: 78.753608%\n140: 74.988095%\n141: 76.082085%\n142: 70.651834%\n143: 74.740981%\n144: 75.270341%\n145: 73.855311%\n146: 68.220252%\n147: 67.349664%\n148: 66.532426%\n149: 66.097416%\n150: 67.831349%\n151: 73.616606%\n152: 62.546898%\n153: 64.235653%\n154: 59.908009%\n155: 64.310786%\n156: 67.454823%\n157: 67.101690%\n158: 72.925685%\n159: 57.776779%\n160: 61.396825%\n161: 67.805014%\n162: 61.471140%\n163: 52.731088%\n164: 54.766373%\n165: 63.541126%\n166: 57.187007%\n167: 57.346459%\n168: 49.902930%\n169: 50.103424%\n170: 52.638598%\n171: 47.559371%\n172: 48.218101%\n173: 49.050061%\n174: 45.922466%\n175: 46.121032%\n176: 46.567571%\n177: 45.378968%\n178: 42.876540%\n179: 49.532648%\n180: 37.863095%\n181: 48.644841%\n182: 50.136752%\n183: 44.071970%\n184: 37.448413%\n185: 31.647436%\n186: 36.735209%\n187: 37.188409%\n188: 35.832112%\n189: 41.878039%\n190: 32.639527%\n191: 39.541667%\n192: 30.133977%\n193: 32.709402%\n194: 38.680819%\n195: 29.349567%\n196: 32.697996%\n197: 24.268926%\n198: 34.317363%\n199: 38.054376%\n200: 42.425422%\n201: 34.282135%\n202: 39.052767%\n203: 31.102259%\n204: 27.595238%\n205: 29.030303%\n206: 32.744048%\n207: 33.871392%\n208: 32.051587%\n209: 38.270896%\n210: 24.289225%\n211: 33.501984%\n212: 36.443459%\n213: 28.004509%\n214: 24.802670%\n215: 34.517857%\n216: 38.839105%\n217: 24.183608%\n218: 29.799548%\n219: 24.202534%\n220: 30.231685%\n221: 28.155053%\n222: 29.850386%\n223: 24.460317%\n224: 29.001263%\n225: 37.509921%\n226: 20.710317%\n227: 29.921454%\n228: 36.644481%\n229: 21.502747%\n230: 21.262266%\n231: 28.358905%\n232: 29.303918%\n233: 14.056985%\n234: 27.015263%\n235: 28.145604%\n236: 23.577991%\n237: 13.874903%\n238: 24.443376%\n239: 17.658730%\n240: 20.470418%\n241: 16.684732%\n242: 31.628608%\n243: 34.696429%\n244: 31.273810%\n245: 21.694444%\n246: 18.503621%\n247: 30.656593%\n248: 12.478896%\n249: 22.892247%\n250: 20.033425%\n251: 23.190629%\n252: 19.017247%\n253: 30.896520%\n254: 26.859418%\n255: 17.375000%\n256: 20.919428%\n257: 14.953755%\n258: 16.796898%\n259: 17.349956%\n260: 20.526141%\n261: 10.093254%\n262: 25.990620%\n263: 25.526252%\n264: 22.876832%\n265: 20.998016%\n266: 13.603050%\n267: 30.738095%\n268: 15.029998%\n269: 19.247156%\n270: 14.408730%\n271: 15.778319%\n272: 22.831349%\n273: 31.722763%\n274: 17.069986%\n275: 20.497572%\n276: 16.408730%\n277: 21.629690%\n278: 22.245421%\n279: 11.718004%\n280: 22.217338%\n281: 20.904762%\n282: 17.282870%\n283: 20.578755%\n284: 13.736153%\n285: 22.474387%\n286: 21.785409%\n287: 14.616300%\n288: 21.076646%\n289: 17.111888%\n290: 13.857601%\n291: 18.957418%\n292: 19.736722%\n293: 17.571123%\n294: 25.201160%\n295: 18.534799%\n296: 21.060897%\n297: 18.919414%\n298: 17.067460%\n299: 17.199592%\n300: 19.115981%\n301: 19.440837%\n302: 16.733516%\n303: 11.038462%\n304: 11.483516%\n305: 12.497100%\n306: 12.724567%\n307: 24.074176%\n308: 20.972555%\n309: 16.708486%\n310: 11.098346%\n311: 19.999251%\n312: 13.652778%\n313: 10.467532%\n314: 17.172675%\n315: 22.561508%\n316: 16.459887%\n317: 13.515568%\n318: 21.805486%\n319: 11.128594%\n320: 13.095474%\n321: 9.594017%\n322: 24.945166%\n323: 12.394841%\n324: 9.623377%\n325: 15.959693%\n326: 23.075216%\n327: 19.623918%\n328: 17.719322%\n329: 19.965201%\n330: 15.148810%\n331: 22.632201%\n332: 12.698413%\n333: 18.957418%\n334: 12.790043%\n335: 14.356865%\n336: 12.454240%\n337: 11.472403%\n338: 12.214161%\n339: 10.682540%\n340: 8.031136%\n341: 23.891595%\n342: 18.505342%\n343: 7.706530%\n344: 11.600580%\n345: 19.344017%\n346: 19.632631%\n347: 10.074786%\n348: 12.349387%\n349: 14.799784%\n350: 20.333333%\n351: 13.130952%\n352: 14.422980%\n353: 17.338980%\n354: 13.856838%\n355: 7.431457%\n356: 15.785714%\n357: 9.418651%\n358: 13.335317%\n359: 7.603175%\n360: 13.011600%\n361: 17.319444%\n362: 13.912879%\n363: 18.287698%\n364: 15.472403%\n365: 16.184524%\n366: 14.445527%\n367: 18.261683%\n368: 16.663420%\n369: 12.136655%\n370: 10.733877%\n371: 10.315657%\n372: 15.166361%\n373: 11.072192%\n374: 13.384921%\n375: 12.960498%\n376: 13.832778%\n377: 13.107323%\n378: 15.979076%\n379: 18.541667%\n380: 7.342172%\n381: 13.527806%\n382: 17.554834%\n383: 8.575758%\n384: 11.021215%\n385: 15.041667%\n386: 15.530844%\n387: 9.201299%\n388: 10.910409%\n389: 16.030303%\n390: 17.420635%\n391: 11.843240%\n392: 5.857323%\n393: 10.230159%\n394: 20.079365%\n395: 8.411103%\n396: 11.476732%\n397: 9.392857%\n398: 11.622405%\n399: 10.317460%\n400: 18.083028%\n401: 16.202076%\n402: 4.484127%\n403: 5.445998%\n404: 10.910714%\n405: 11.370726%\n406: 7.261350%\n407: 20.122461%\n408: 12.555708%\n409: 15.757326%\n410: 14.872711%\n411: 14.095238%\n412: 14.392483%\n413: 10.505952%\n414: 16.989774%\n415: 6.793831%\n416: 5.158120%\n417: 14.960317%\n418: 7.928571%\n419: 8.090965%\n420: 8.907814%\n421: 12.654762%\n422: 14.317460%\n423: 11.004329%\n424: 14.174784%\n425: 7.113095%\n426: 6.486472%\n427: 10.190476%\n428: 12.500000%\n429: 12.932234%\n430: 6.089161%\n431: 6.275669%\n432: 9.930556%\n433: 9.556929%\n434: 14.666667%\n435: 10.351551%\n436: 10.424603%\n437: 4.107143%\n438: 10.362485%\n439: 15.238276%\n440: 18.880952%\n441: 15.285007%\n442: 7.050144%\n443: 9.480880%\n444: 9.121032%\n445: 15.537698%\n446: 13.141414%\n447: 15.459596%\n448: 19.187229%\n449: 10.058969%\n450: 9.504690%\n451: 9.402778%\n452: 9.557692%\n453: 12.644841%\n454: 11.661131%\n455: 6.565171%\n456: 13.492063%\n457: 5.998016%\n458: 3.075397%\n459: 16.722222%\n460: 11.498016%\n461: 3.126374%\n462: 15.083028%\n463: 9.570887%\n464: 11.686508%\n465: 9.095418%\n466: 7.646756%\n467: 12.986111%\n468: 4.611111%\n469: 7.228535%\n470: 5.452256%\n471: 5.606838%\n472: 12.071123%\n473: 10.523504%\n474: 6.755952%\n475: 4.487179%\n476: 8.892913%\n477: 6.265568%\n478: 11.500000%\n479: 7.071429%\n480: 9.289683%\n481: 7.172619%\n482: 9.664433%\n483: 8.065476%\n484: 8.353175%\n485: 11.710165%\n486: 13.898810%\n487: 9.823163%\n488: 7.559524%\n489: 5.444444%\n490: 5.083333%\n491: 6.224567%\n492: 13.350885%\n493: 12.369048%\n494: 15.057234%\n495: 4.333333%\n496: 3.125000%\n497: 3.898990%\n498: 8.049451%\n499: 5.595238%\n500: 8.166667%\n501: 8.303447%\n502: 3.214286%\n503: 13.223776%\n504: 3.775183%\n505: 7.339286%\n506: 9.771520%\n507: 12.345599%\n508: 9.431624%\n509: 1.428571%\n510: 5.934524%\n511: 3.162393%\n512: 6.611472%\n513: 9.170024%\n514: 4.888889%\n515: 4.409091%\n516: 9.257021%\n517: 7.398990%\n518: 8.114164%\n519: 6.710012%\n520: 6.190476%\n521: 12.078380%\n522: 9.865079%\n523: 8.136905%\n524: 10.301587%\n525: 4.243978%\n"}, {"output_type": "stream", "name": "stdout", "text": "526: 1.714286%\n527: 5.708333%\n528: 4.055556%\n529: 9.090354%\n530: 9.595599%\n531: 14.547009%\n532: 12.479853%\n533: 5.412698%\n534: 15.432540%\n535: 6.051282%\n536: 9.710498%\n537: 5.705128%\n538: 6.888889%\n539: 10.708333%\n540: 9.621212%\n541: 4.655303%\n542: 13.259310%\n543: 10.821429%\n544: 15.436508%\n545: 11.801768%\n546: 12.387363%\n547: 5.736111%\n548: 5.333333%\n549: 5.277778%\n550: 4.412698%\n551: 5.456710%\n552: 10.863095%\n553: 3.787879%\n554: 4.608392%\n555: 15.044900%\n556: 8.408120%\n557: 7.708333%\n558: 7.636600%\n559: 5.551768%\n560: 9.866939%\n561: 15.869228%\n562: 10.547619%\n563: 11.259615%\n564: 11.456349%\n565: 5.416667%\n566: 8.135032%\n567: 5.575092%\n568: 11.738095%\n569: 11.255772%\n570: 9.441850%\n571: 3.467643%\n572: 3.585859%\n573: 11.829060%\n574: 9.529762%\n575: 6.690476%\n576: 6.085317%\n577: 8.182720%\n578: 18.054293%\n579: 11.111111%\n580: 8.690476%\n581: 7.476190%\n582: 11.977564%\n583: 4.960317%\n584: 9.051282%\n585: 4.757631%\n586: 17.500000%\n587: 7.412393%\n588: 4.468254%\n589: 5.547619%\n590: 6.537698%\n591: 14.057540%\n592: 7.000000%\n593: 11.339466%\n594: 13.577922%\n595: 4.479853%\n596: 5.621212%\n597: 11.666667%\n598: 6.560897%\n599: 7.101190%\n600: 5.757992%\n601: 5.454365%\n602: 9.297619%\n603: 3.150183%\n604: 12.158730%\n605: 6.833333%\n606: 4.331530%\n607: 6.964286%\n608: 4.335317%\n609: 8.958333%\n610: 11.748959%\n611: 4.523810%\n612: 5.569444%\n613: 15.229243%\n614: 6.500000%\n615: 4.759615%\n616: 8.474359%\n617: 7.180556%\n618: 4.436508%\n619: 4.912879%\n620: 5.420635%\n621: 8.966270%\n622: 2.676282%\n623: 7.361111%\n624: 12.488095%\n625: 4.976190%\n626: 11.888278%\n627: 6.041667%\n628: 7.214286%\n629: 12.450397%\n630: 3.424298%\n631: 11.277473%\n632: 4.388889%\n633: 10.231061%\n634: 7.633478%\n635: 5.583333%\n636: 4.492063%\n637: 8.555556%\n638: 11.945513%\n639: 4.125000%\n640: 3.376984%\n641: 9.698593%\n642: 8.053141%\n643: 3.474747%\n644: 4.502165%\n645: 8.166667%\n646: 4.145299%\n647: 5.263889%\n648: 17.140873%\n649: 7.496212%\n650: 8.164683%\n651: 2.894841%\n652: 5.983516%\n653: 8.750000%\n654: 10.170330%\n655: 3.668831%\n656: 10.039683%\n657: 9.603175%\n658: 12.467949%\n659: 5.607143%\n660: 6.309524%\n661: 6.068529%\n662: 7.500000%\n663: 8.430556%\n664: 11.411616%\n665: 14.729853%\n666: 10.884615%\n667: 10.186508%\n668: 7.305556%\n669: 3.217949%\n670: 4.964286%\n671: 8.315657%\n672: 5.380952%\n673: 4.742063%\n674: 5.381133%\n675: 6.168651%\n676: 14.190476%\n677: 8.023504%\n678: 1.625000%\n679: 5.470113%\n680: 4.236111%\n681: 3.928571%\n682: 5.172494%\n683: 4.162393%\n684: 3.363095%\n685: 3.708333%\n686: 1.634615%\n687: 3.809524%\n688: 0.000000%\n689: 4.513889%\n690: 1.916667%\n691: 7.801282%\n692: 2.728175%\n693: 7.468254%\n694: 6.079545%\n695: 4.958333%\n696: 3.500000%\n697: 4.251374%\n698: 4.557595%\n699: 11.208333%\n700: 1.388889%\n701: 0.833333%\n702: 4.446123%\n703: 4.342949%\n704: 4.333333%\n705: 9.674603%\n706: 2.722222%\n707: 2.638889%\n708: 6.884615%\n709: 8.918831%\n710: 6.388278%\n711: 5.081585%\n712: 4.191850%\n713: 6.311688%\n714: 5.912698%\n715: 1.537698%\n716: 5.944444%\n717: 3.880952%\n718: 5.047619%\n719: 2.944444%\n720: 2.986111%\n721: 5.527778%\n722: 1.269841%\n723: 7.847222%\n724: 2.676282%\n725: 8.491453%\n726: 4.561508%\n727: 5.833333%\n728: 8.412698%\n729: 1.454545%\n730: 9.602564%\n731: 4.620726%\n732: 4.983516%\n733: 3.839286%\n734: 0.833333%\n735: 4.347222%\n736: 6.319444%\n737: 2.222222%\n738: 2.470238%\n739: 7.835498%\n740: 9.621212%\n741: 9.435897%\n742: 5.890568%\n743: 4.738095%\n744: 5.666667%\n745: 2.904457%\n746: 12.954545%\n747: 4.484127%\n748: 4.333333%\n749: 3.820513%\n750: 5.019841%\n751: 2.868742%\n752: 8.500000%\n753: 5.090840%\n754: 9.394841%\n755: 3.325397%\n756: 6.793831%\n757: 3.625000%\n758: 4.967949%\n759: 5.661075%\n760: 4.388889%\n761: 6.583333%\n762: 6.883117%\n763: 2.478355%\n764: 4.458333%\n765: 11.347222%\n766: 6.612179%\n767: 8.174603%\n768: 7.260101%\n769: 9.492063%\n770: 7.333333%\n771: 4.025974%\n772: 7.440171%\n773: 6.250000%\n774: 7.664072%\n775: 6.666667%\n776: 7.936508%\n777: 4.841270%\n778: 11.361111%\n779: 5.117063%\n780: 4.888889%\n781: 6.076770%\n782: 6.000000%\n783: 7.626679%\n784: 2.745726%\n785: 1.839286%\n786: 2.666667%\n787: 2.142857%\n788: 5.459707%\n789: 3.380952%\n790: 2.833333%\n791: 10.222222%\n792: 12.992063%\n793: 3.479853%\n794: 3.652778%\n795: 4.541667%\n796: 7.196970%\n797: 1.071429%\n798: 2.569444%\n799: 11.930556%\n800: 3.194444%\n801: 8.781011%\n802: 1.625000%\n803: 9.138889%\n804: 6.442335%\n805: 12.722222%\n806: 7.217949%\n807: 6.718254%\n808: 6.376068%\n809: 15.444444%\n810: 7.182234%\n811: 3.839286%\n812: 5.833333%\n813: 4.047619%\n814: 3.631313%\n815: 3.055556%\n816: 13.841450%\n817: 7.961760%\n818: 1.815476%\n819: 4.305556%\n820: 4.888889%\n821: 6.150794%\n822: 5.416667%\n823: 5.384615%\n824: 10.513889%\n825: 11.427961%\n826: 2.936508%\n827: 7.095238%\n828: 8.611111%\n829: 4.241453%\n830: 4.583333%\n831: 2.919192%\n832: 4.761905%\n833: 3.071429%\n834: 5.566850%\n835: 5.537879%\n836: 7.142857%\n837: 10.902778%\n838: 5.250000%\n839: 10.023810%\n840: 4.603175%\n841: 3.380952%\n842: 7.926587%\n843: 5.103535%\n844: 11.932234%\n845: 3.654762%\n846: 8.192460%\n847: 2.797619%\n848: 8.888889%\n849: 5.208333%\n850: 2.307692%\n851: 3.717949%\n852: 1.428571%\n853: 2.301282%\n854: 5.978175%\n855: 4.273504%\n856: 5.848901%\n857: 10.444444%\n858: 0.833333%\n859: 14.180556%\n860: 5.390929%\n861: 0.454545%\n862: 2.769231%\n863: 4.097222%\n864: 3.547619%\n865: 5.416667%\n866: 4.343434%\n867: 6.376068%\n868: 7.361111%\n869: 8.460498%\n870: 3.222222%\n871: 1.010101%\n872: 6.511905%\n873: 8.551282%\n874: 4.384615%\n875: 8.412879%\n876: 6.511905%\n877: 0.972222%\n878: 3.589466%\n879: 3.878968%\n880: 8.785714%\n881: 9.273504%\n882: 3.900794%\n883: 3.075397%\n884: 9.105339%\n885: 3.005952%\n886: 2.408425%\n887: 10.761905%\n888: 6.025794%\n889: 6.432540%\n890: 5.333333%\n891: 7.222222%\n892: 2.777778%\n893: 10.336691%\n894: 7.325758%\n895: 10.674603%\n896: 3.511905%\n897: 10.317460%\n898: 7.505828%\n899: 5.463980%\n900: 5.301768%\n901: 0.357143%\n902: 5.888889%\n903: 5.811688%\n904: 2.380952%\n905: 3.539683%\n906: 0.741758%\n907: 1.458333%\n908: 7.380952%\n909: 1.666667%\n910: 4.158120%\n911: 3.625000%\n912: 3.551282%\n913: 4.166667%\n914: 2.714286%\n915: 8.404942%\n916: 0.916667%\n917: 1.750000%\n918: 0.714286%\n919: 5.555556%\n920: 8.569444%\n921: 4.597403%\n922: 5.250000%\n923: 3.690476%\n924: 6.541667%\n925: 5.317460%\n926: 7.468254%\n927: 5.833333%\n928: 1.357143%\n929: 3.210012%\n930: 3.777778%\n931: 5.575397%\n932: 3.853175%\n933: 1.769231%\n934: 0.500000%\n935: 1.000000%\n936: 1.180556%\n937: 1.793831%\n938: 4.450272%\n939: 1.884921%\n940: 1.180556%\n941: 0.972222%\n942: 6.666667%\n943: 1.000000%\n944: 4.955128%\n945: 5.555556%\n946: 5.291667%\n947: 12.936508%\n948: 1.565657%\n949: 0.500000%\n950: 1.190476%\n951: 0.555556%\n952: 1.269841%\n953: 3.333333%\n954: 1.269841%\n955: 2.500000%\n956: 5.547619%\n957: 4.967949%\n958: 6.130952%\n959: 8.380952%\n960: 2.023810%\n961: 3.390568%\n962: 3.888889%\n963: 3.125000%\n964: 5.310897%\n965: 3.162393%\n966: 2.686508%\n967: 6.388889%\n968: 7.500000%\n969: 1.958333%\n970: 4.404762%\n971: 8.717949%\n972: 7.932234%\n973: 3.847222%\n974: 3.005952%\n975: 7.894841%\n976: 3.055556%\n977: 3.125000%\n978: 3.333333%\n979: 2.464161%\n980: 5.154762%\n981: 7.094933%\n982: 5.206349%\n983: 5.083333%\n984: 1.666667%\n985: 1.009615%\n986: 3.505952%\n987: 4.061508%\n988: 1.384615%\n989: 5.625000%\n990: 3.946609%\n991: 0.416667%\n992: 2.291667%\n993: 2.880952%\n994: 3.214286%\n995: 1.426768%\n996: 3.079365%\n997: 8.101190%\n998: 0.555556%\n999: 6.492424%\n1000: 3.214286%\n1001: 3.333333%\n1002: 4.079365%\n1003: 7.190476%\n1004: 3.333333%\n1005: 7.658730%\n1006: 5.102564%\n1007: 6.833333%\n1008: 3.505828%\n1009: 5.833333%\n1010: 4.315476%\n1011: 5.361111%\n1012: 5.333333%\n1013: 6.037879%\n1014: 2.638889%\n1015: 0.357143%\n1016: 3.888889%\n1017: 4.529637%\n1018: 1.666667%\n1019: 3.388889%\n1020: 3.775669%\n1021: 1.412698%\n1022: 6.042735%\n1023: 6.656746%\n1024: 3.134921%\n1025: 3.269231%\n1026: 5.940171%\n1027: 1.555556%\n1028: 11.180556%\n1029: 4.898990%\n1030: 5.000000%\n1031: 4.988276%\n1032: 8.260101%\n1033: 1.071429%\n1034: 2.458333%\n1035: 4.690476%\n1036: 3.527778%\n1037: 6.964286%\n1038: 2.842949%\n1039: 0.714286%\n1040: 0.454545%\n1041: 3.539683%\n1042: 5.833333%\n1043: 7.934524%\n1044: 3.208333%\n1045: 1.680556%\n1046: 6.625000%\n1047: 7.555556%\n1048: 5.000000%\n1049: 5.752165%\n1050: 7.009615%\n1051: 1.625000%\n1052: 2.410589%\n1053: 3.595238%\n1054: 3.666667%\n1055: 1.428571%\n1056: 3.541667%\n1057: 6.388889%\n1058: 3.575397%\n1059: 1.666667%\n1060: 7.277778%\n1061: 2.388889%\n1062: 5.000000%\n1063: 3.769231%\n"}, {"output_type": "stream", "name": "stdout", "text": "1064: 6.666667%\n1065: 5.289072%\n1066: 8.468254%\n1067: 8.769841%\n1068: 2.539683%\n1069: 8.144841%\n1070: 1.458333%\n1071: 7.555556%\n1072: 4.111111%\n1073: 5.508658%\n1074: 2.606838%\n1075: 5.103175%\n1076: 1.894841%\n1077: 4.444444%\n1078: 3.541667%\n1079: 3.176282%\n1080: 6.088980%\n1081: 7.162698%\n1082: 4.047619%\n1083: 3.023504%\n1084: 2.815171%\n1085: 1.458333%\n1086: 5.000000%\n1087: 2.845238%\n1088: 2.260101%\n1089: 1.454545%\n1090: 8.625000%\n1091: 8.523810%\n1092: 11.755952%\n1093: 4.472222%\n1094: 8.985806%\n1095: 10.055556%\n1096: 4.333333%\n1097: 3.766234%\n1098: 3.005952%\n1099: 6.736111%\n1100: 6.388889%\n1101: 8.373016%\n1102: 0.555556%\n1103: 4.166667%\n1104: 2.847222%\n1105: 1.625000%\n1106: 5.722222%\n1107: 4.428571%\n1108: 1.666667%\n1109: 11.602564%\n1110: 8.595238%\n1111: 1.654457%\n1112: 6.031746%\n1113: 1.825397%\n1114: 6.500000%\n1115: 5.246032%\n1116: 5.357143%\n1117: 2.222222%\n1118: 1.666667%\n1119: 5.213675%\n1120: 1.555556%\n1121: 4.246032%\n1122: 5.000000%\n1123: 3.413947%\n1124: 3.222222%\n1125: 3.242063%\n1126: 3.916667%\n1127: 4.214286%\n1128: 0.625000%\n1129: 4.888889%\nTest error: 7.339236%\n"}], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "\n", "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.4.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}